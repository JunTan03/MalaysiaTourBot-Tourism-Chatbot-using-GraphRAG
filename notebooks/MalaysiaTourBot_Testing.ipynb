{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2b630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shuek\\OneDrive\\Documents\\DEGREE Y3S3\\TNL\\TNL Project\\TNL\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import libraries needed\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import base64\n",
    "from PIL import Image\n",
    "from neo4j import GraphDatabase\n",
    "from groq import Groq\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image as IPyImage, display\n",
    "from ragas.metrics import Faithfulness, ContextRelevance, ResponseRelevancy\n",
    "from ragas.dataset_schema import SingleTurnSample \n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b593456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established.\n"
     ]
    }
   ],
   "source": [
    "# Neo4j Connection Details\n",
    "URI = os.getenv(\"NEO4J_URI\")\n",
    "AUTH = (\"neo4j\", os.getenv(\"NEO4J_PASSWORD\"))\n",
    "\n",
    "driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "driver.verify_connectivity()\n",
    "print(\"Connection established.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4dd481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the Groq API key for calling the MLLM later from Groq.\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize the Groq client\n",
    "groq_client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6debf10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Load the embedding model from huggingface and use the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = SentenceTransformer(\"BAAI/bge-m3\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Gemini 2.0 Flash model from Google AI Studio API as LLM evaluator for RAGAS evaluation\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "config = {\n",
    "    \"model\": \"gemini-2.0-flash\",  \n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": None,\n",
    "    \"top_p\": 0.8,\n",
    "}\n",
    "\n",
    "# Initialize with Google AI Studio\n",
    "evaluator_llm = LangchainLLMWrapper(ChatGoogleGenerativeAI(\n",
    "    model=config[\"model\"],\n",
    "    temperature=config[\"temperature\"],\n",
    "    max_tokens=config[\"max_tokens\"],\n",
    "    top_p=config[\"top_p\"],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Google text embedding model for RAGAS evaluation\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",  # Google's text embedding model\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text embedding function\n",
    "def generate_text_embedding(text):\n",
    "    embedding = model.encode(text, convert_to_numpy=True)\n",
    "    return embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve top K nodes from Neo4j based on the text embedding\n",
    "def retrieve_top_k_nodes(query, top_k=5):\n",
    "    embedding = generate_text_embedding(query)\n",
    "    results = []\n",
    "\n",
    "    index_map = {\n",
    "        \"Place\": \"place_index\",\n",
    "        \"Content\": \"content_index\",\n",
    "        \"Type\": \"type_index\",\n",
    "        \"State\": \"state_index\",\n",
    "    }\n",
    "\n",
    "    with driver.session() as session:\n",
    "        for label, index_name in index_map.items():\n",
    "            result = session.run(\"\"\"\n",
    "                CALL db.index.vector.queryNodes($index_name, 5, $embedding)\n",
    "                YIELD node, score\n",
    "                RETURN $label AS source, node, score, elementId(node) AS node_id\n",
    "            \"\"\", label=label, index_name=index_name, embedding=embedding)\n",
    "\n",
    "            for record in result:\n",
    "                data = record.data()\n",
    "                node = data[\"node\"]\n",
    "                node[\"__id\"] = data[\"node_id\"]\n",
    "                results.append({\n",
    "                    \"source\": data[\"source\"],\n",
    "                    \"score\": data[\"score\"],\n",
    "                    \"node\": node\n",
    "                })\n",
    "\n",
    "    results.sort(key=lambda x: -x['score'])\n",
    "    return results[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand a place node to include its details\n",
    "def expand_place_node(place_id):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (p:Place)\n",
    "            WHERE elementId(p) = $id\n",
    "            OPTIONAL MATCH (p)-[:HAS_TYPE]->(t:Type)\n",
    "            OPTIONAL MATCH (p)-[:IN_STATE]->(s:State)\n",
    "            OPTIONAL MATCH (p)-[:HAS_EN_CONTENT]->(c_en:Content)\n",
    "            OPTIONAL MATCH (p)-[:HAS_MS_CONTENT]->(c_ms:Content)\n",
    "            RETURN \n",
    "                p.title AS title,\n",
    "                t.name AS type,\n",
    "                s.name AS state,\n",
    "                c_en.text AS en_content,\n",
    "                c_ms.text AS ms_content,\n",
    "                p.image_url AS image_url\n",
    "        \"\"\", id=place_id)\n",
    "\n",
    "        expanded = []\n",
    "        for r in result:\n",
    "            expanded.append({\n",
    "                \"title\": r[\"title\"],\n",
    "                \"type\": r.get(\"type\", \"\"),\n",
    "                \"state\": r.get(\"state\", \"\"),\n",
    "                \"en_content\": r.get(\"en_content\", \"\"),\n",
    "                \"ms_content\": r.get(\"ms_content\", \"\"),\n",
    "                \"image_url\": r.get(\"image_url\", \"\")\n",
    "            })\n",
    "\n",
    "    return expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to expand a matched node by traversing to related Place nodes\n",
    "def expand_related_nodes(match, max_places=5):\n",
    "    label = match[\"source\"]\n",
    "    node = match[\"node\"]\n",
    "    node_id = node[\"__id\"]\n",
    "\n",
    "    places = []\n",
    "\n",
    "    with driver.session() as session:\n",
    "        # If the matched node is already a Place, directly expand and return it\n",
    "        if label == \"Place\":\n",
    "            return expand_place_node(node_id)\n",
    "\n",
    "        # If the matched node is a State, find Places in that state\n",
    "        elif label == \"State\":\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (s:State)<-[:IN_STATE]-(p:Place)\n",
    "                WHERE elementId(s) = $id\n",
    "                RETURN elementId(p) AS pid\n",
    "                LIMIT $limit\n",
    "            \"\"\", id=node_id, limit=max_places)\n",
    "\n",
    "        # If the matched node is a Type, find Places of that type\n",
    "        elif label == \"Type\":\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (t:Type)<-[:HAS_TYPE]-(p:Place)\n",
    "                WHERE elementId(t) = $id\n",
    "                RETURN elementId(p) AS pid\n",
    "                LIMIT $limit\n",
    "            \"\"\", id=node_id, limit=max_places)\n",
    "\n",
    "        # If the matched node is Content (description), find associated Places\n",
    "        elif label == \"Content\":\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (c:Content)<-[:HAS_EN_CONTENT|HAS_MS_CONTENT]-(p:Place)\n",
    "                WHERE elementId(c) = $id\n",
    "                RETURN elementId(p) AS pid\n",
    "                LIMIT $limit\n",
    "            \"\"\", id=node_id, limit=max_places)\n",
    "\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "        for r in result:\n",
    "            pid = r[\"pid\"]\n",
    "            places.extend(expand_place_node(pid))\n",
    "\n",
    "    return places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eaf239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graphrag_answer(query, top_k=5, max_related=5):\n",
    "\n",
    "    # Step 1: Retrieve top-k relevant nodes from the graph based on semantic similarity\n",
    "    matches = retrieve_top_k_nodes(query, top_k=top_k)\n",
    "\n",
    "    context_strings = []\n",
    "    context_places = []  # Places passed into LLM\n",
    "    related_count = 0\n",
    "\n",
    "    # Step 2: Expand each matched node to find related Place nodes\n",
    "    for m in matches:\n",
    "        if related_count >= max_related:\n",
    "            break\n",
    "        \n",
    "        # Retrieve related places based on the matched node\n",
    "        related = expand_related_nodes(m, max_places=max_related - related_count)\n",
    "\n",
    "        for item in related:\n",
    "            if related_count >= max_related:\n",
    "                break\n",
    "            # Format each place‚Äôs information into context\n",
    "            context_strings.append(\n",
    "                f\"--- Context ---\\n\"\n",
    "                f\"Title   : {item['title']}\\n\"\n",
    "                f\"Type    : {item['type']}\\n\"\n",
    "                f\"State   : {item['state']}\\n\"\n",
    "                f\"Content (Malay)  : {item['ms_content']}\\n\\n\"\n",
    "                f\"Content (English): {item['en_content']}\"\n",
    "            )\n",
    "            context_places.append(item)\n",
    "            related_count += 1\n",
    "\n",
    "    # Step 3: Combine all contexts into one block for the LLM prompt\n",
    "    context_block = \"\\n\\n\".join(context_strings)\n",
    "\n",
    "     # Step 4: Construct  prompt with rules for answering\n",
    "    prompt = f\"\"\"\n",
    "You are a knowledgeable and friendly assistant specializing in Malaysian tourism.\n",
    "Your goal is to answer user questions based on the context provided below. Please follow these guidelines carefully:\n",
    "\n",
    "1. If the user asks in *Malay, respond fully in **Malay*.\n",
    "2. If the user asks in *English, respond fully in **English*.\n",
    "3. If the query contains a mix of Malay and English, determine which language dominates:  \n",
    "   - If *60% or more of the words or sentence structure* are in *English, respond in **English*.  \n",
    "   - If *60% or more* are in *Malay, respond in **Malay*.\n",
    "4. If the question is *not related to Malaysian tourism*, politely inform the user that you can only assist with Malaysian tourism topics.\n",
    "5. Do **NOT** answer any questions that are:\n",
    "   - harmful\n",
    "   - sexual\n",
    "   - offensive\n",
    "   - unrelated to Malaysian tourism\n",
    "   Politely decline such questions.\n",
    "6. If the user expresses negative emotions (e.g., sad, depressed, hopeless), respond with gentle encouragement and recommend positive travel destinations to uplift them.\n",
    "\n",
    "Context:\n",
    "{context_block}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Step 5: Call the LLM (via Groq API) with the prompt\n",
    "    completion = groq_client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3,\n",
    "        max_completion_tokens=512,\n",
    "    )\n",
    "\n",
    "    raw_answer = completion.choices[0].message.content.strip()\n",
    "    answer_lower = raw_answer.lower()\n",
    "\n",
    "    # Step 6: Track which place titles were mentioned in the LLM's response\n",
    "    mentioned_places = []\n",
    "    seen_titles = set()\n",
    "    for place in context_places:\n",
    "        title = place['title']\n",
    "        if title.lower() in answer_lower and title.lower() not in seen_titles:\n",
    "            mentioned_places.append(place)\n",
    "            seen_titles.add(title.lower())\n",
    "\n",
    "    # Step 7: Collect image references (only unique ones)\n",
    "    image_refs = []\n",
    "    seen_image_urls = set()\n",
    "    for place in mentioned_places:\n",
    "        image_url = place.get(\"image_url\", \"\")\n",
    "        if image_url and image_url not in seen_image_urls:\n",
    "            image_refs.append(f\"\\nüì∑ {place['title']} image: {image_url}\")\n",
    "            seen_image_urls.add(image_url)\n",
    "\n",
    "    # Step 8: Return final answer with image links, original matches, context, and referenced places\n",
    "    final_answer = raw_answer + \"\\n\" + \"\\n\".join(image_refs)\n",
    "\n",
    "    return final_answer, matches, context_block, mentioned_places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fcee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DataFrame with 50 questions for evaluation \n",
    "evaluation_df = pd.DataFrame({\n",
    "    \"Question\": [\n",
    "        \"Apakah pantai yang sesuai untuk bercuti di Terengganu?\",\n",
    "        \"Cadangan tempat pelancongan di Melaka?\",\n",
    "        \"Cadangan tempat pelancongan di Johor?\",\n",
    "        \"Cadangan tempat pelancongan di Sabah?\",\n",
    "        \"Cadangan tempat pelancongan di Sarawak?\",\n",
    "        \"Cadangan tempat pelancongan di Selangor?\",\n",
    "        \"Cadangan tempat pelancongan di Labuan?\",\n",
    "        \"Cadangan tempat pelancongan di Kuala Lumpur?\",\n",
    "        \"Cadangan tempat pelancongan di Putrajaya?\",\n",
    "        \"Cadangan tempat pelancongan di Penang?\",\n",
    "        \"Cadangan tempat pelancongan di Terengganu?\",\n",
    "        \"Cadangan tempat pelancongan di Kelantan?\",\n",
    "        \"Cadangan tempat pelancongan di Kedah?\",\n",
    "        \"Cadangan tempat pelancongan di Perlis?\",\n",
    "        \"Cadangan tempat pelancongan di Perak?\",\n",
    "        \"Cadangan tempat pelancongan di Negeri Sembilan?\",\n",
    "        \"Cadangan tempat pelancongan di Ipoh?\",\n",
    "        \"Cadangan tempat pelancongan di Kuantan?\",\n",
    "        \"Cadangan tempat pelancongan di Kota Kinabalu?\",\n",
    "        \"Gunung tertinggi di Sabah?\",\n",
    "        \"Senarai Nama Pulau-pulau yang boleh snorkeling\",\n",
    "        \"Tempat menarik untuk bawa anak-anak?\",\n",
    "        \"Tempat bersejarah di George Town?\",\n",
    "        \"Aktiviti alam semula jadi di Pahang?\",\n",
    "        \"Apa yang boleh dibuat di Genting Highlands?\",\n",
    "        \"Apa tempat menarik di Johor Bahru?\",\n",
    "        \"Cadangan lokasi camping selamat?\",\n",
    "        \"Festival budaya di Malaysia?\",\n",
    "        \"Tempat menarik di Cameron Highlands?\",\n",
    "        \"Ada aktiviti eco-tourism di Sarawak?\",\n",
    "        \"Tempat percutian keluarga di Malaysia?\",\n",
    "        \"Apa pulau terbaik untuk diving?\",\n",
    "        \"Tempat heritage UNESCO di Malaysia?\",\n",
    "        \"Apakah zoo terbaik di Malaysia?\",\n",
    "        \"Ada taman tema air yang besar?\",\n",
    "        \"Tempat melihat matahari terbenam?\",\n",
    "        \"Apa yang menarik tentang Taman Negara?\",\n",
    "        \"Boleh ceritakan tentang Gunung Kinabalu?\",\n",
    "        \"Apakah aktiviti yang boleh dibuat di Langkawi Sky Bridge?\",\n",
    "        \"Apa yang boleh dilihat di Penang Hill?\",\n",
    "        \"Apa keistimewaan Mount Mulu?\",\n",
    "        \"Apa yang ada di Kuala Gandah Elephant Sanctuary?\",\n",
    "        \"Apakah jenis tempat Gua Tempurung?\",\n",
    "        \"Boleh jelaskan tentang Bako National Park?\",\n",
    "        \"Apakah Cameron Highlands sesuai untuk bercuti?\",\n",
    "        \"Tempat apa itu Sipadan Island?\",\n",
    "        \"Aktiviti menarik di Sunway Lagoon?\",\n",
    "        \"The Habitat Penang Hill ini tempat apa?\",\n",
    "        \"Nak tahu tentang Colmar Tropicale di mana?\",\n",
    "        \"Apa tarikan utama di Legoland Malaysia?\",\n",
    "    ]\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98795e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Starting GraphRAG evaluation on 50 questions ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [10:54<00:00, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Evaluation complete. Averages over 50 questions:\n",
      " - Average Context Relevance  : 0.8150\n",
      " - Average Faithfulness       : 0.7208\n",
      " - Average Answer Relevance   : 0.7666\n",
      "\n",
      "‚úÖ Results saved to: MalaysiaTourGraphRAG_eval.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = \"MalaysiaTourGraphRAG_eval.json\"\n",
    "results = []\n",
    "\n",
    "# Accumulators to compute average scores across all evaluated questions\n",
    "total_context_relevance = 0.0\n",
    "total_faithfulness = 0.0\n",
    "total_response_relevance = 0.0\n",
    "count = 0\n",
    "\n",
    "print(\"\\nüîç Starting GraphRAG evaluation on 50 questions ...\")\n",
    "\n",
    "questions = evaluation_df[\"Question\"].tolist()\n",
    "\n",
    "# Loop through each evaluation question\n",
    "for q in tqdm(questions, desc=\"Evaluating\"):\n",
    "    try:\n",
    "        answer, _, context, _ = generate_graphrag_answer(q)\n",
    "\n",
    "        # Prepare the input sample for RAGAS evaluation\n",
    "        sample = SingleTurnSample(\n",
    "            user_input=q,\n",
    "            response=answer,\n",
    "            retrieved_contexts=[context],\n",
    "        )\n",
    "\n",
    "        # Run each RAGAS metric \n",
    "        context_relevance_score = await ContextRelevance(llm=evaluator_llm).single_turn_ascore(sample)\n",
    "        faithfulness_score = await Faithfulness(llm=evaluator_llm).single_turn_ascore(sample)\n",
    "        response_relevancy_score = await ResponseRelevancy(llm=evaluator_llm, embeddings=evaluator_embeddings).single_turn_ascore(sample)\n",
    "\n",
    "        # Update score accumulators\n",
    "        total_context_relevance += context_relevance_score\n",
    "        total_faithfulness += faithfulness_score\n",
    "        total_response_relevance += response_relevancy_score\n",
    "        count += 1\n",
    "\n",
    "        result_entry = {\n",
    "            \"question\": q,\n",
    "            \"generated_answer\": answer,\n",
    "            \"retrieved_context\": context,\n",
    "            \"context_relevance_score\": context_relevance_score,\n",
    "            \"faithfulness_score\": faithfulness_score,\n",
    "            \"answer_relevance_score\": response_relevancy_score\n",
    "        }\n",
    "\n",
    "        results.append(result_entry)\n",
    "\n",
    "         # Save intermediate results to file\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error for question: {q} ‚Üí {e}\")\n",
    "\n",
    "# Final average metrics\n",
    "if count > 0:\n",
    "    avg_context_relevance = total_context_relevance / count\n",
    "    avg_faithfulness = total_faithfulness / count\n",
    "    avg_response_relevance = total_response_relevance / count\n",
    "\n",
    "    print(f\"\\nüìä Evaluation complete. Averages over {count} questions:\")\n",
    "    print(f\" - Average Context Relevance  : {avg_context_relevance:.4f}\")\n",
    "    print(f\" - Average Faithfulness       : {avg_faithfulness:.4f}\")\n",
    "    print(f\" - Average Answer Relevance   : {avg_response_relevance:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No successful evaluations to compute averages.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44daedca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TNL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
